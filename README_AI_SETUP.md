# ğŸ¤– AI Setup for CardiagnoAI

## Choose Your AI Backend

CardiagnoAI supports **3 options** for AI functionality:

### Option 1: ğŸ¦™ Ollama (RECOMMENDED - Easiest!)

**Best for:** Everyone, especially beginners

âœ… **Pros:**
- No Docker required
- Simple Windows installer
- Free and private
- Fast setup (5 minutes)
- Great models available

âŒ **Cons:**
- Requires download (~5GB models)
- Needs decent computer (8GB+ RAM)

**Setup:**
1. Run `SETUP_OLLAMA.bat` OR
2. Follow `OLLAMA_SETUP.md`

---

### Option 2: ğŸ  LocalAI (Advanced)

**Best for:** Advanced users with Docker

âœ… **Pros:**
- More model options
- Highly customizable
- Free and private

âŒ **Cons:**
- Requires Docker
- More complex setup
- Larger resource usage

**Setup:**
Follow `LOCALAI_SETUP.md`

---

### Option 3: â˜ï¸ OpenAI (Cloud)

**Best for:** Quick testing, don't want local setup

âœ… **Pros:**
- No installation
- Very fast
- Latest models

âŒ **Cons:**
- Costs money ($0.01-0.03 per scan)
- Data sent to OpenAI
- Requires internet
- Privacy concerns

**Setup:**
1. Get API key from https://platform.openai.com/api-keys
2. Edit `src/config/localai.js`:
   ```javascript
   enabled: false,  // Disable local AI
   ```
3. Edit `src/services/visionService.js` line 6:
   ```javascript
   const OPENAI_API_KEY = 'sk-your-actual-key-here';
   ```
4. Edit `src/services/aiService.js` line 5:
   ```javascript
   const OPENAI_API_KEY = 'sk-your-actual-key-here';
   ```

---

## ğŸš€ Quick Start (Recommended Path)

### For Most Users: Use Ollama

```bash
# 1. Run the setup script
SETUP_OLLAMA.bat

# 2. Start CardiagnoAI
npm start

# 3. Start using!
```

That's it! Your app now has:
- âœ… Private AI (data stays on your computer)
- âœ… Free unlimited scans and chats
- âœ… Works offline
- âœ… No API costs

---

## ğŸ“Š Comparison Table

| Feature | Ollama | LocalAI | OpenAI |
|---------|--------|---------|--------|
| **Setup Time** | 5 min | 30 min | 2 min |
| **Cost** | Free | Free | ~$10/month |
| **Privacy** | 100% Private | 100% Private | Cloud-based |
| **Internet** | Optional | Optional | Required |
| **Quality** | Excellent | Excellent | Excellent |
| **Speed** | Fast | Fast | Very Fast |
| **Difficulty** | â­ Easy | â­â­â­ Hard | â­ Easy |

---

## ğŸ¯ Which Should I Choose?

### Choose **Ollama** if:
- âœ… You want easy setup
- âœ… You care about privacy
- âœ… You don't want monthly costs
- âœ… You have 8GB+ RAM
- âœ… You want offline capability

### Choose **LocalAI** if:
- âœ… You're comfortable with Docker
- âœ… You want maximum customization
- âœ… You need specific models
- âœ… You're technically advanced

### Choose **OpenAI** if:
- âœ… You want instant setup
- âœ… You don't mind cloud processing
- âœ… You're okay with costs
- âœ… You want the absolute best quality
- âœ… You're just testing the app

---

## ğŸ”„ Switching Between Options

You can easily switch:

**To use Ollama/LocalAI:**
```javascript
// src/config/localai.js
enabled: true,
baseURL: 'http://localhost:11434',  // Ollama
// OR
baseURL: 'http://localhost:8080',   // LocalAI
```

**To use OpenAI:**
```javascript
// src/config/localai.js
enabled: false,
```

---

## âš¡ Quick Commands

### Ollama
```bash
# Install models
ollama pull llama3.2
ollama pull llava

# List models
ollama list

# Test
ollama run llama3.2 "Hello!"
```

### LocalAI
```bash
# Start server
cd LocalAI
docker-compose up -d

# Check status
docker ps
```

### OpenAI
```bash
# Test API key
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer YOUR_API_KEY"
```

---

## ğŸ†˜ Need Help?

1. **Ollama Issues:** Check `OLLAMA_SETUP.md`
2. **LocalAI Issues:** Check `LOCALAI_SETUP.md`
3. **OpenAI Issues:** Visit https://platform.openai.com/docs
4. **App Issues:** Check `README.md`

---

## ğŸ‰ Recommended Setup

**For best experience:**

1. **Install Ollama** (5 minutes)
2. **Download models** (llama3.2 + llava)
3. **Start using CardiagnoAI**
4. **Enjoy free, private AI!**

---

**Ready to start?** Run `SETUP_OLLAMA.bat` now! ğŸš€
